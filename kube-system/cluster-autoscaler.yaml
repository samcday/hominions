---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-autoscaler
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
rules:
  - apiGroups: [""]
    resources: ["events", "endpoints"]
    verbs: ["create", "patch"]
  - apiGroups: [""]
    resources: ["pods/eviction"]
    verbs: ["create"]
  - apiGroups: [""]
    resources: ["pods/status"]
    verbs: ["update"]
  - apiGroups: [""]
    resources: ["endpoints"]
    resourceNames: ["cluster-autoscaler"]
    verbs: ["get", "update"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["watch", "list", "get", "update"]
  - apiGroups: [""]
    resources:
      - "namespaces"
      - "pods"
      - "services"
      - "replicationcontrollers"
      - "persistentvolumeclaims"
      - "persistentvolumes"
    verbs: ["watch", "list", "get"]
  - apiGroups: ["extensions"]
    resources: ["replicasets", "daemonsets"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["watch", "list"]
  - apiGroups: ["apps"]
    resources: ["statefulsets", "replicasets", "daemonsets"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses", "csinodes", "csistoragecapacities", "csidrivers"]
    verbs: ["watch", "list", "get"]
  - apiGroups: ["batch", "extensions"]
    resources: ["jobs"]
    verbs: ["get", "list", "watch", "patch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["create"]
  - apiGroups: ["coordination.k8s.io"]
    resourceNames: ["cluster-autoscaler"]
    resources: ["leases"]
    verbs: ["get", "update"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["create","list","watch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["cluster-autoscaler-status", "cluster-autoscaler-priority-expander"]
    verbs: ["delete", "get", "update", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-autoscaler
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-autoscaler
    namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: cluster-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-autoscaler
    namespace: kube-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    app: cluster-autoscaler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      serviceAccountName: cluster-autoscaler
      tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
      containers:
        - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.25.0
          name: cluster-autoscaler
          resources:
            limits:
              cpu: 100m
              memory: 300Mi
            requests:
              cpu: 100m
              memory: 300Mi
          command:
            - ./cluster-autoscaler
            - --cloud-provider=hetzner
            - --nodes=1:5:cx11:fsn1:home
          env:
            - name: HCLOUD_SSH_KEY
              value: mine
          envFrom:
            - configMapRef:
                name: hcloud-cloud-init
            - secretRef:
                name: hcloud-token
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hcloud-provisioner
  namespace: kube-system
  labels:
    k8s-app: hcloud-provisioner
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      name: hcloud-provisioner
  template:
    metadata:
      labels:
        name: hcloud-provisioner
    spec:
      containers:
        - name: hcloud-provisioner
          image: alpine:3
          command:
            - /bin/ash
            - -c
            - |-
              set -uexo pipefail

              apk add curl jq
              curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
              chmod +x kubectl && mv kubectl /bin
              wget -O- https://github.com/hetznercloud/cli/releases/download/v1.30.3/hcloud-linux-386.tar.gz | tar -C /bin -zxvf -
              curl -L https://fly.io/install.sh | sh
              export FLYCTL_INSTALL="/root/.fly"
              export PATH="$FLYCTL_INSTALL/bin:$PATH"
              wget -O- https://get.k3sup.dev | sh
              cp /ssh-key/hcloud-worker /tmp
              chmod 600 /tmp/hcloud-worker
              ssh="ssh -F /dev/null -i /tmp/hcloud-worker -oConnectTimeout=3 -oServerAliveInterval=5 -oStrictHostKeyChecking=no -oUserKnownHostsFile=/dev/null -T"
              apk add openssh-client

              while true; do
                for name in $(hcloud server list -l hcloud/node-group=home -o noheader -o columns=name ); do
                  ip=$(hcloud server ip $name)
                  if ! kubectl get nodes/$name; then
                    kubectl apply -f- <<HERE
              apiVersion: v1
              kind: Node
              metadata:
                name: $name
              HERE
                  fi

                  until $ssh $ip date; do
                    sleep 1
                  done

                  if ! $ssh $ip systemctl is-active tailscaled; then
                    $ssh $ip 'curl -fsSL https://tailscale.com/install.sh | sh' || continue
                  fi

                  pod_cidr=$(kubectl get nodes $name -o 'jsonpath={.spec.podCIDR}')

                  if ! $ssh $ip tailscale status; then
                    $ssh $ip tailscale up --login-server=https://samcday-headscale.fly.dev/ --accept-dns --accept-routes --authkey=$TS_AUTH_KEY --advertise-routes=$pod_cidr || continue
                  fi

                  internal_ip=$($ssh $ip tailscale ip -4)

                  # fly console into headscale, enable the route.
                  # can maybe replace this with autoApprovers ACL thing?
                  node_id=$(flyctl ssh console -a samcday-headscale -C 'headscale node list -o json-line' | jq -r ". | map(select(.ip_addresses | contains([\"$internal_ip\"]))) | .[].id")
                  flyctl ssh console -a samcday-headscale -C "headscale route enable -a -i $node_id"

                  if ! $ssh $ip systemctl is-active k3s-agent; then
                    k3sup join --server-host 100.64.0.2 --host $internal_ip --k3s-channel=v1.25 --k3s-extra-args="--node-ip=$internal_ip --node-label 'node-role.kubernetes.io/hcloud=' --node-taint 'node-role.kubernetes.io/hcloud:NoSchedule' --kubelet-arg=cloud-provider=external" --ssh-key=/tmp/hcloud-worker || continue
                  fi
                done

                sleep 30s
              done
          envFrom:
            - secretRef:
                name: hcloud-token
            - secretRef:
                name: tailscale-auth
            - secretRef:
                name: fly-auth
          resources:
            limits:
              cpu: '1'
              memory: 256Mi
            requests:
              cpu: 100m
              memory: 64Mi
          volumeMounts:
            - name: ssh-key
              mountPath: /ssh-key
      serviceAccountName: hcloud-provisioner
      terminationGracePeriodSeconds: 3
      volumes:
        - name: ssh-key
          secret:
            secretName: hcloud-worker-ssh-key
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: hcloud-provisioner
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: hcloud-provisioner
rules:
- apiGroups: [""]
  resources: [nodes]
  verbs: ["*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: hcloud-provisioner
subjects:
- kind: ServiceAccount
  name: hcloud-provisioner
  namespace: kube-system
roleRef:
  kind: ClusterRole
  name: hcloud-provisioner
  apiGroup: rbac.authorization.k8s.io
